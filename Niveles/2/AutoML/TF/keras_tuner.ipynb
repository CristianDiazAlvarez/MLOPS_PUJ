{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "El desarrollo de modelos de aprendizaje automático suele ser un proceso iterativo. Comienza con un diseño inicial y luego se reconfigura hasta que obtenga un modelo que pueda ser entrenado de manera eficiente en términos de tiempo y recursos de calcular. Como ya sabrá, estas configuraciones que ajusta se llaman híper parámetros. Estas son las variables que rigen el proceso de entrenamiento y la topología de un modelo ML. Estos permanecen constantes sobre el proceso de entrenamiento e impactan directamente el rendimiento de su programa ML.\n",
    "\n",
    "El proceso de encontrar el conjunto óptimo de hiperparámetros se llama *ajuste de híper parámetros *o *hipertuning *, y es una parte esencial de un pipeline de aprendizaje automático. Sin ella, puede terminar con un modelo que tiene parámetros innecesarios y tarda demasiado en entrenar.\n",
    "\n",
    "Los hiperparámetros son de dos tipos:\n",
    "1. **Híper parámetros modelo** que influyen en la selección del modelo, como el número y el ancho de las capas ocultas\n",
    "\n",
    "2. **Híper parámetros del Algoritmo** que influyen en la velocidad y la calidad del algoritmo de aprendizaje, como la tasa de aprendizaje para el descenso de gradiente estocástico (SGD) y el número de vecinos más cercanos para un clasificador de vecinos más cercanos (KNN).\n",
    "\n",
    "Para modelos más complejos, el número de hiperparámetros puede aumentar dramáticamente y ajustarlos manualmente puede ser bastante desafiante.\n",
    "\n",
    "En este Notebook, se presenta el ajuste de híper parámetros con [Keras Tuner](https://keras-team.github.io/keras-tuner/), un paquete Keras que automatiza este proceso. A modo de comparación, primero se entrena un modelo de referencia con hiperparámetros preseleccionados, luego rehacer el proceso con hiperparámetros ajustados. Algunos de los ejemplos y discusiones aquí se toman del [tutorial oficial proporcionado por Tensorflow](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb#scrollto=skwlozkpfgaj)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReV_UXOgCZvx"
   },
   "source": [
    "## Descargar y preparar el conjunto de datos\n",
    "\n",
    "Primero cargamos el [conjunto de datos Mnist de moda](https://github.com/zalandoresearch/fashion-mnist). Utilizará esto para entrenar un modelo de aprendizaje automático que clasifica imágenes de ropa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ysAmHLZoDld7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 18:13:41.534257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 18:13:41.776208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-09 18:13:41.776243: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-09 18:13:43.025869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-09 18:13:43.026047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-09 18:13:43.026056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import keras\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHlHs9Wj_PUM",
    "outputId": "94f7a03b-9ca5-4428-b835-ef6d9eb9d050",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset and split into train and test sets\n",
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHkQOzHLoKNA"
   },
   "source": [
    "Para el preprocesamiento, se normalizan los valores de píxeles para que el entrenamiento converja más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bLVhXs3xrUD0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hM19_JWD6eF"
   },
   "source": [
    "## Rendimiento de línea de base\n",
    "\n",
    "Como se mencionó, primero tendrá un rendimiento de línea de base utilizando parámetros seleccionados arbitrariamente para que pueda comparar los resultados más adelante. En aras del tiempo y los límites de recursos proporcionados, simplemente construirá una red neuronal densa superficial (DNN) como se muestra a continuación. Esto es para demostrar los conceptos sin involucrar enormes conjuntos de datos y largos tiempos de ajuste y entrenamiento. Como verá más adelante, incluso los modelos pequeños pueden tardar un tiempo en ajustarse. Puede extender los conceptos aquí cuando puede construir modelos más complejos en sus propios proyectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqbYwwukkA6z",
    "outputId": "aec9c2f1-a54c-498d-c8f0-b391e5af575a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 18:13:53.789967: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-09 18:13:53.790008: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-09 18:13:53.790042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (91561e3127f9): /proc/driver/nvidia/version does not exist\n",
      "2023-03-09 18:13:53.790396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Build the baseline model using the Sequential API\n",
    "b_model = keras.Sequential()\n",
    "b_model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "b_model.add(keras.layers.Dense(units=512, activation='relu', name='dense_1')) # You will tune this layer later\n",
    "b_model.add(keras.layers.Dropout(0.2))\n",
    "b_model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Print model summary\n",
    "b_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAlb_KxTK50d"
   },
   "source": [
    "Como se muestra, codificamos todos los hiperparámetros al declarar las capas. Estos incluyen el número de unidades ocultas, activación y abandono. Verá cómo puede ajustar automáticamente algunos de estos un poco más tarde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM354GIBKdf0"
   },
   "source": [
    "Luego configuremos la pérdida, las métricas y el optimizador. La tasa de aprendizaje también es un hiperparámetro que puede ajustar automáticamente, pero por ahora, configuremos en `0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Lp58Ety3pLj2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the training parameters\n",
    "b_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FxeAlZlLpHI"
   },
   "source": [
    "Con todas las configuraciones establecidas, puede comenzar a entrenar el modelo. Hemos establecido el número de épocas en 10, pero no dude en aumentarlo si tiene más tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1JjZ-FdLXZ3",
    "outputId": "4ed88e65-8fa3-41d9-fb27-b5db3b5ccecb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 18:13:54.452162: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5136 - accuracy: 0.8163 - val_loss: 0.4168 - val_accuracy: 0.8497\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3926 - accuracy: 0.8568 - val_loss: 0.3822 - val_accuracy: 0.8619\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3560 - accuracy: 0.8676 - val_loss: 0.3536 - val_accuracy: 0.8727\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3339 - accuracy: 0.8767 - val_loss: 0.3397 - val_accuracy: 0.8754\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3200 - accuracy: 0.8818 - val_loss: 0.3423 - val_accuracy: 0.8759\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3057 - accuracy: 0.8868 - val_loss: 0.3232 - val_accuracy: 0.8837\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2949 - accuracy: 0.8909 - val_loss: 0.3184 - val_accuracy: 0.8840\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2819 - accuracy: 0.8940 - val_loss: 0.3121 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2717 - accuracy: 0.8992 - val_loss: 0.3453 - val_accuracy: 0.8778\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2660 - accuracy: 0.9004 - val_loss: 0.3505 - val_accuracy: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fabdb540700>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of training epochs.\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Train the model\n",
    "b_model.fit(img_train, label_train, epochs=NUM_EPOCHS, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6LALxGwMtkV"
   },
   "source": [
    "Finalmente, desea ver cómo se desempeña este modelo de referencia en el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBnZ2tFbpxgC",
    "outputId": "859937e0-6b4f-4b06-b9c3-ae11090a8b9a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3811 - accuracy: 0.8677\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on the test set\n",
    "b_eval_dict = b_model.evaluate(img_test, label_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YCfzg0IM9b6"
   },
   "source": [
    "Definamos una función de ayuda para mostrar los resultados, por lo que es más fácil comparar más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vt2dWs0NxnUn",
    "outputId": "260322aa-708a-4413-a042-36d3546cd4eb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BASELINE MODEL:\n",
      "number of units in 1st Dense layer: 512\n",
      "learning rate for the optimizer: 0.0010000000474974513\n",
      "loss: 0.38111504912376404\n",
      "accuracy: 0.8676999807357788\n"
     ]
    }
   ],
   "source": [
    "# Define helper function\n",
    "def print_results(model, model_name, eval_dict):\n",
    "    '''\n",
    "    Prints the values of the hyparameters to tune, and the results of model evaluation\n",
    "\n",
    "    Args:\n",
    "    model (Model) - Keras model to evaluate\n",
    "    model_name (string) - arbitrary string to be used in identifying the model\n",
    "    eval_dict (dict) -  results of model.evaluate\n",
    "    '''\n",
    "    print(f'\\n{model_name}:')\n",
    "\n",
    "    print(f'number of units in 1st Dense layer: {model.get_layer(\"dense_1\").units}')\n",
    "    print(f'learning rate for the optimizer: {model.optimizer.lr.numpy()}')\n",
    "\n",
    "    for key,value in eval_dict.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "# Print results for baseline model\n",
    "print_results(b_model, 'BASELINE MODEL', b_eval_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH-RLK3Wxt_X"
   },
   "source": [
    "Eso es todo para obtener los resultados para un solo conjunto de hiperparámetros. Como puede ver, este proceso puede ser tedioso si desea probar diferentes conjuntos de parámetros. Por ejemplo, ¿mejorará su modelo si usa `learning_rate = 0.00001` y` units = 128`?  El proceso será aún más difícil si decide también ajustar el dropout y probar otras funciones de activación también. Keras Tuner resuelve este problema al tener una API para buscar automáticamente el conjunto óptimo. Solo tendrá que configurarlo una vez que luego esperar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oyczDXqtWjI"
   },
   "source": [
    "## Keras Tuner\n",
    "\n",
    "Para realizar hipertuning con Keras Tuner, deberá:\n",
    "\n",
    "* Definir el modelo\n",
    "* Seleccionar qué hiperparámetros sintonizar\n",
    "* Definir su espacio de búsqueda\n",
    "* Definir la estrategia de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_leAIdFKAxAD",
    "outputId": "df35c1bf-0455-4e47-88a0-00b1809880eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5YEL2H2Ax3e"
   },
   "source": [
    "### Defina el modelo\n",
    "\n",
    "El modelo que configuró para hipertuning se llama *hipermodelo *. Cuando construye este modelo, define el espacio de búsqueda de hiperparameter además de la arquitectura del modelo.\n",
    "\n",
    "Puede definir un hipermodelo a través de dos enfoques:\n",
    "\n",
    "* Mediante el uso de una función de constructor de modelos\n",
    "* [Subclase de la clase `Hypermodel`](https://keras-team.github.io/keras-tuner/#you-can-use-a-hypermodel-subclass-instead-of-a-model-building--función) de la API de Keras Tuner\n",
    "\n",
    "\n",
    "Acá se muestra el primer enfoque: utilizando una función de constructor de modelos para definir el modelo de clasificación de imágenes. Esta función devuelve un modelo compilado y utiliza hiperparámetros que define en línea para ajustar el modelo.\n",
    "\n",
    "La función a continuación básicamente construye el mismo modelo que usó anteriormente. La diferencia es que hay dos hiperparámetros que están configurados para el ajuste:\n",
    "\n",
    "* El número de unidades ocultas de la primera capa densa\n",
    "* La tasa de aprendizaje del ADAM Optimizer\n",
    "\n",
    "Verá que esto se hace con un objeto HyperParameters que configura el hiperparámetro que le gustaría ajustar. Para este ejercicio, lo harás:\n",
    "\n",
    "* Se usa el método `int()` para definir el espacio de búsqueda para las unidades densas. Esto le permite establecer un valor mínimo y máximo, así como el tamaño de paso al incrementar entre estos valores.\n",
    "\n",
    "* Se usa el método `Choice ()` para la tasa de aprendizaje. Esto le permite definir valores discretos para incluir en el espacio de búsqueda.\n",
    "\n",
    "Puede ver todos los métodos disponibles y su uso de muestras en [Documentación oficial](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/#hyperparameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZQKodC-jtsva",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    '''\n",
    "    Builds the model and sets up the hyperparameters to tune.\n",
    "\n",
    "    Args:\n",
    "    hp - Keras tuner object\n",
    "\n",
    "    Returns:\n",
    "    model with hyperparameters to tune\n",
    "    '''\n",
    "\n",
    "    # Initialize the Sequential API and start stacking the layers\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu', name='dense_1'))\n",
    "\n",
    "    # Add next layers\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J1VYw4q3x0b"
   },
   "source": [
    "## Instanciar el Tuner y realizar hipertuning\n",
    "\n",
    "Ahora que tiene el generador de modelos, puede definir cómo el Tuner puede encontrar el conjunto óptimo de híper parámetros, también llamado estrategia de búsqueda. Keras Tuner tiene [cuatro sintonizadores](https://keras-team.github.io/keras-tuner/documentation/tuners/) Disponible con estrategias incorporadas-`randomsearch`,` Hyperband`, `bayesianoptimization`, y` Sklearn`.\n",
    "\n",
    "En este tutorial, usará el Tuner de hiperband. Hyperband es un algoritmo desarrollado específicamente para la optimización de los híper parametros. Utiliza la asignación de recursos adaptativos y la parada temprana para converger rápidamente en un modelo de alto rendimiento. Esto se realiza utilizando un soporte de estilo de campeonato deportivo en el que el algoritmo entrena una gran cantidad de modelos para algunas épocas y transporta solo la mitad de los modelos de alto rendimiento a la siguiente ronda. Puede leer sobre la intuición detrás del algoritmo en la Sección 3 de [este documento](https://arxiv.org/pdf/1603.06560.pdf).\n",
    "\n",
    "Hyperband determina el número de modelos para entrenar en un soporte calculando 1 + log <Sub> `Factor` </sub> (` max_epochs`) y redondeándolo al entero más cercano. Verá estos parámetros (es decir, `factor` y` max_epochs` pasados al inicializador a continuación). Además, también deberá definir lo siguiente para instanciar el sintonizador de Hyperband:\n",
    "\n",
    "* El hipermodelo (construido por la función de su constructor de modelos)\n",
    "* El `Objective` para optimizar (por ejemplo, precisión de validación)\n",
    "* Un `Directory` para guardar registros y puntos de control para cada prueba (configuración del modelo) se ejecuta durante la búsqueda de hiperparameter. Si vuelve a ejecutar la búsqueda de hiperparameter, el sintonizador Keras usa el estado existente de estos registros para reanudar la búsqueda. Para deshabilitar este comportamiento, pase un argumento adicional `sobrescribir = true` al instancias del Tuner.\n",
    "* El `Project_Name` para diferenciar con otras ejecuciones. Esto se utilizará como un nombre de subdirectorio en el 'Directorio'.\n",
    "\n",
    "Puede consultar la [documentación](https://keras.io/api/keras_tuner/tuners/hyperband/) para otros argumentos en los que puede transmitir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oichQFly6Y46",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='kt_dir',\n",
    "                     project_name='kt_hyperband')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij3hGcp4e8QG"
   },
   "source": [
    "Veamos un resumen de los híper parámetros que ajustará:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmkJOPp5WkiG",
    "outputId": "02bd9450-efe2-4137-b262-d574beeb56d8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# Display hypertuning settings\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwhBdXx0Ekj8"
   },
   "source": [
    "Puede pasar un callback dejar de entrenar antes cuando una métrica no está mejorando. A continuación, definimos un calback [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/earlystopping) para monitorear la pérdida de validación y dejar de entrenar si no está mejorando después de 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WT9IkS9NEjLc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKghEo15Tduy"
   },
   "source": [
    "Ahora ejecutará la búsqueda de híper parametros. Los argumentos para el método de búsqueda son los mismos que los utilizados para `tf.keras.model.fit` además del calback anterior. Esto tomará alrededor de 10 minutos en correr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSBQcTHF9cKt",
    "outputId": "704a3331-a74d-4cb0-da2f-79aefbbe1ea1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 00s]\n",
      "val_accuracy: 0.8901666402816772\n",
      "\n",
      "Best val_accuracy So Far: 0.8923333287239075\n",
      "Total elapsed time: 00h 12m 47s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Perform hypertuning\n",
    "tuner.search(img_train, label_train, epochs=NUM_EPOCHS, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewN6WBDYWvRw"
   },
   "source": [
    "Puede obtener el modelo de mejor rendimiento con [get_best_hyperparameters()](https://keras-team.github.io/keras-tuner/documentation/tuners/#get_best_hyperparameters-method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iG0zIuP5WuTI",
    "outputId": "15c69e64-e6a1-48a8-cd24-09fcec021384",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 416 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters from the results\n",
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lak_ylf88xBv"
   },
   "source": [
    "## Construir y entrenar el modelo\n",
    "\n",
    "Ahora que tiene el mejor conjunto de hiperparámetros, puede reconstruir el hipermodelo con estos valores y volver a entrenarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McO82AXOuxXh",
    "outputId": "a23dfbec-afd6-45cb-c5bd-a3f011f216f2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 416)               326560    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 416)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                4170      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330,730\n",
      "Trainable params: 330,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters\n",
    "h_model = tuner.hypermodel.build(best_hps)\n",
    "h_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l64WP7Rau1lm",
    "outputId": "e8530cf0-f3db-443d-80d9-ac1d9f99a7c5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5168 - accuracy: 0.8168 - val_loss: 0.4238 - val_accuracy: 0.8471\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3908 - accuracy: 0.8584 - val_loss: 0.3577 - val_accuracy: 0.8709\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3557 - accuracy: 0.8695 - val_loss: 0.3581 - val_accuracy: 0.8726\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3342 - accuracy: 0.8755 - val_loss: 0.3655 - val_accuracy: 0.8593\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3182 - accuracy: 0.8813 - val_loss: 0.3396 - val_accuracy: 0.8760\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3057 - accuracy: 0.8864 - val_loss: 0.3361 - val_accuracy: 0.8798\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2946 - accuracy: 0.8895 - val_loss: 0.3232 - val_accuracy: 0.8835\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2862 - accuracy: 0.8936 - val_loss: 0.3349 - val_accuracy: 0.8797\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2794 - accuracy: 0.8965 - val_loss: 0.3171 - val_accuracy: 0.8856\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2677 - accuracy: 0.8991 - val_loss: 0.3329 - val_accuracy: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faba6ff5c70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the hypertuned model\n",
    "h_model.fit(img_train, label_train, epochs=NUM_EPOCHS, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqU5ZVAaag2v"
   },
   "source": [
    "Luego obtendrá su rendimiento contra el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9E0BTp9Ealjb",
    "outputId": "b18c2281-649d-4c15-c883-e45bec051732",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3557 - accuracy: 0.8723\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the hypertuned model against the test set\n",
    "h_eval_dict = h_model.evaluate(img_test, label_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQRpPHZsz-eC"
   },
   "source": [
    "Podemos comparar los resultados que obtuvimos con el modelo de referencia que utilizamos al comienzo. Los resultados pueden variar, pero generalmente obtendrá un modelo que tiene menos unidades en la capa densa, mientras que tiene pérdida y precisión comparables. Esto indica que redujo el tamaño del modelo y ahorró recursos de cómputo, al tiempo que tiene más o menos la misma precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjVYPOw6MH5d",
    "outputId": "56fbb501-8157-4b71-e15e-2e00489c567e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BASELINE MODEL:\n",
      "number of units in 1st Dense layer: 512\n",
      "learning rate for the optimizer: 0.0010000000474974513\n",
      "loss: 0.38111504912376404\n",
      "accuracy: 0.8676999807357788\n",
      "\n",
      "HYPERTUNED MODEL:\n",
      "number of units in 1st Dense layer: 416\n",
      "learning rate for the optimizer: 0.0010000000474974513\n",
      "loss: 0.35569459199905396\n",
      "accuracy: 0.8723000288009644\n"
     ]
    }
   ],
   "source": [
    "# Print results of the baseline and hypertuned model\n",
    "print_results(b_model, 'BASELINE MODEL', b_eval_dict)\n",
    "print_results(h_model, 'HYPERTUNED MODEL', h_eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of C3_W1_Lab_1_Keras_Tuner.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
